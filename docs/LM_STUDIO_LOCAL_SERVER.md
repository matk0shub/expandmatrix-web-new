# LM Studio - Local Server nenÃ­ spuÅ¡tÄ›nÃ½

## ğŸ” ProblÃ©m
LM Studio aplikace bÄ›Å¾Ã­, ale **Local Server nenÃ­ spuÅ¡tÄ›nÃ½**. Proto curl na port 1234 selhÃ¡vÃ¡.

## âœ… Å˜eÅ¡enÃ­

### 1. OtevÅ™ete LM Studio aplikaci
- UjistÄ›te se, Å¾e mÃ¡te naÄtenÃ½ model **openai/gpt-oss-20b**

### 2. SpusÅ¥te Local Server
- V LM Studio kliknÄ›te na **"Local Server"** v levÃ©m menu
- KliknÄ›te na **"Start Server"** 
- Server by mÄ›l bÄ›Å¾et na portu **1234** (nebo jinÃ©m, kterÃ½ uvidÃ­te v UI)

### 3. OvÄ›Å™te, Å¾e server bÄ›Å¾Ã­
```bash
curl http://localhost:1234/v1/models
```
MÄ›li byste vidÄ›t JSON s informacemi o vaÅ¡em modelu.

### 4. Pokud port nenÃ­ 1234
- V LM Studio Local Server UI uvidÃ­te skuteÄnÃ½ port
- Aktualizujte konfiguraci:

```bash
# Aktualizujte .env soubor
sed -i '' 's|LMSTUDIO_BASE_URL=.*|LMSTUDIO_BASE_URL=http://localhost:SKUTECNY_PORT/v1|' /Users/matty/Documents/ai_projects/cipher/cipher/.env

# Aktualizujte MCP konfiguraci
jq '.mcpServers.cipher.env.LMSTUDIO_BASE_URL="http://localhost:SKUTECNY_PORT/v1"' ~/.cursor/mcp.json | tee ~/.cursor/mcp.json
```

### 5. Test Cipher
```bash
cd /Users/matty/Documents/ai_projects/cipher/cipher
node dist/src/app/index.cjs --mode mcp
```

## ğŸš¨ DÅ¯leÅ¾itÃ© poznÃ¡mky

- **Model musÃ­ bÃ½t naÄtenÃ½** v LM Studio pÅ™ed spuÅ¡tÄ›nÃ­m Local Serveru
- **Local Server musÃ­ bÃ½t spuÅ¡tÄ›nÃ½** - samotnÃ¡ aplikace nestaÄÃ­
- **Port se mÅ¯Å¾e liÅ¡it** od 1234 - vÅ¾dy zkontrolujte v LM Studio UI

## ğŸ”§ RychlÃ© ovÄ›Å™enÃ­

Po spuÅ¡tÄ›nÃ­ Local Serveru zkuste:
```bash
# NajdÄ›te LM Studio port
for p in 1234 1235 5000 8000 9000; do 
  echo "Testing port $p:"
  curl -s --max-time 2 "http://127.0.0.1:$p/v1/models" && echo "FOUND on port $p" && break
done
```

---

**Status: âš ï¸ ÄŒEKÃ NA SPUÅ TÄšNÃ LOCAL SERVERU V LM STUDIO**

